{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DeepFakes: Reenactment using Pix2Pix GAN\n",
    "- We will leverage a live feed as input\n",
    "- The live video feed would be used to extract facial landmarks\n",
    "- The landmarks would then be used to generate reenacted frames of Mr. Barak Obama"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from imutils import video\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CROP_SIZE = 256\n",
    "DOWNSAMPLE_RATIO = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility Methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def reshape_for_polyline(array):\n",
    "    \"\"\"Reshape image so that it works with polyline.\"\"\"\n",
    "    return np.array(array, np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "\n",
    "def resize(image):\n",
    "    \"\"\"Crop and resize image for pix2pix.\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    if height != width:\n",
    "        # crop to correct ratio\n",
    "        size = min(height, width)\n",
    "        oh = (height - size) // 2\n",
    "        ow = (width - size) // 2\n",
    "        cropped_image = image[oh:(oh + size), ow:(ow + size)]\n",
    "        image_resize = cv2.resize(cropped_image, (CROP_SIZE, CROP_SIZE), interpolation = cv2.INTER_LINEAR)\n",
    "        return image_resize\n",
    "\n",
    "def rescale_frame(frame):\n",
    "    dim = (256, 256)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(r'shape_predictor_68_face_landmarks.dat')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generator = keras.models.load_model(r'gen_pix2pix_deepfake_obama.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quick Sanity Check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from data_utils import plot_sample_images\n",
    "import tensorflow as tf\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (8,8),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_sample_images(generator,'data/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility Method for Live Feed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_landmarks(black_image,gray,faces):\n",
    "    for face in faces:\n",
    "        detected_landmarks = predictor(gray, face).parts()\n",
    "        landmarks = [[p.x * DOWNSAMPLE_RATIO, p.y * DOWNSAMPLE_RATIO] for p in detected_landmarks]\n",
    "\n",
    "        jaw = reshape_for_polyline(landmarks[0:17])\n",
    "        left_eyebrow = reshape_for_polyline(landmarks[22:27])\n",
    "        right_eyebrow = reshape_for_polyline(landmarks[17:22])\n",
    "        nose_bridge = reshape_for_polyline(landmarks[27:31])\n",
    "        lower_nose = reshape_for_polyline(landmarks[30:35])\n",
    "        left_eye = reshape_for_polyline(landmarks[42:48])\n",
    "        right_eye = reshape_for_polyline(landmarks[36:42])\n",
    "        outer_lip = reshape_for_polyline(landmarks[48:60])\n",
    "        inner_lip = reshape_for_polyline(landmarks[60:68])\n",
    "\n",
    "        color = (255, 255, 255)\n",
    "        thickness = 3\n",
    "\n",
    "        cv2.polylines(black_image, [jaw], False, color, thickness)\n",
    "        cv2.polylines(black_image, [left_eyebrow], False, color, thickness)\n",
    "        cv2.polylines(black_image, [right_eyebrow], False, color, thickness)\n",
    "        cv2.polylines(black_image, [nose_bridge], False, color, thickness)\n",
    "        cv2.polylines(black_image, [lower_nose], True, color, thickness)\n",
    "        cv2.polylines(black_image, [left_eye], True, color, thickness)\n",
    "        cv2.polylines(black_image, [right_eye], True, color, thickness)\n",
    "        cv2.polylines(black_image, [outer_lip], True, color, thickness)\n",
    "        cv2.polylines(black_image, [inner_lip], True, color, thickness)\n",
    "    return black_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rescale_frame(frame):\n",
    "    dim = (256, 256)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_obama(landmarks):\n",
    "    landmarks = (landmarks/127.5)-1\n",
    "    landmarks = tf.image.resize(landmarks, [256,256]).numpy()\n",
    "    fake_imgs = generator.predict(np.expand_dims(landmarks,axis=0))\n",
    "    return fake_imgs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's Start Faking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fps = video.FPS().start()\n",
    "k = 0\n",
    "display_plots = True\n",
    "display_cv2 = True\n",
    "while True:\n",
    "    k += 1\n",
    "    ret, frame = cap.read(0)\n",
    "    if np.all(np.array(frame.shape)):\n",
    "        frame_resize = cv2.resize(frame, None, fx=1 / DOWNSAMPLE_RATIO, fy=1 / DOWNSAMPLE_RATIO)\n",
    "        gray = cv2.cvtColor(frame_resize, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray, 1)\n",
    "        black_image = np.zeros(frame.shape, np.uint8)\n",
    "        landmarks = get_landmarks(black_image.copy(),gray,faces)\n",
    "        img_tgt = (landmarks/127.5)-1\n",
    "        img_tgt = tf.image.resize(img_tgt, [256,256]).numpy()\n",
    "        obama = generator.predict(np.expand_dims(img_tgt,axis=0))[0]\n",
    "        try:\n",
    "            obama = 0.5 * obama + 0.5\n",
    "            gen_imgs = np.concatenate([np.expand_dims(cv2.cvtColor(rescale_frame(frame_resize), cv2.COLOR_RGB2BGR),axis=0), \n",
    "                                       np.expand_dims(rescale_frame(obama),axis=0), \n",
    "                                       np.expand_dims(rescale_frame(landmarks),axis=0)])\n",
    "            if display_plots:\n",
    "                titles = ['Live', 'Generated', 'Landmarks']\n",
    "                rows, cols = 1, 3\n",
    "                fig, axs = plt.subplots(rows, cols)\n",
    "                for j in range(cols):\n",
    "                    if j!=1:\n",
    "                        axs[j].imshow(gen_imgs[j].astype(int))\n",
    "                    else:\n",
    "                        axs[j].imshow(gen_imgs[j])\n",
    "                    axs[j].set_title(titles[j])\n",
    "                    axs[j].axis('off')\n",
    "                plt.show()\n",
    "            if display_cv2:\n",
    "                cv2.imshow('synthetic obama', cv2.cvtColor(gen_imgs[1], cv2.COLOR_BGR2RGB))\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        fps.update()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "fps.stop()\n",
    "print('[INFO] elapsed time (total): {:.2f}'.format(fps.elapsed()))\n",
    "print('[INFO] approx. FPS: {:.2f}'.format(fps.fps()))\n",
    "\n",
    "#sess.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap.release()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Frame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "z = np.concatenate([gen_imgs[0].astype(int),\n",
    "                    (255*gen_imgs[1]).astype(int),\n",
    "                    gen_imgs[2].astype(int)],axis=1)\n",
    "plt.imshow(z)\n",
    "plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}