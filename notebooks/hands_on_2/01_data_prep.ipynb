{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"data_prep.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNITixD1bvcg34lrEJ1sn/b"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Preparation\n","\n","- Pix2Pix GAN is a pair-wise setup where we need to provide a pair for input/output sample for training data-point\n","- For current Deep-Fakes pipeline, out training pair would have facial landmarks as input and video frame as output\n","- We will make use of ``opencv`` and ``dlib`` for handling video frames and getting facial landmarks respectively"],"metadata":{}},{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/raghavbali/deep_fakes_tutorial/blob/main/notebooks/hands_on_2/01_data_prep.ipynb)"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import os\n","import cv2\n","import dlib\n","import numpy as np\n","from imutils import video"],"outputs":[],"metadata":{"id":"GSnq8-Bzkyme"}},{"cell_type":"code","execution_count":null,"source":["DOWNSAMPLE_RATIO = 4"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def reshape_array(array):\n","    return np.array(array, np.int32).reshape((-1, 1, 2))\n","\n","\n","def prepare_data(video_file_path, detector, predictor, num_samples=400, downsample_ratio = DOWNSAMPLE_RATIO):\n","    \"\"\"\n","    Utility to prepare data for pix2pix based deepfake.\n","    Output is a set of directories with original frames \n","    and their corresponding facial landmarks\n","    Parameters:\n","        video_file_path : path to video to be analysed\n","        num_samples : number of frames/samples to be extracted\n","    \"\"\"\n","\n","    # create output directories\n","    os.makedirs('original', exist_ok=True)\n","    os.makedirs('landmarks', exist_ok=True)\n","\n","    # get video capture object\n","    cap = cv2.VideoCapture(video_file_path)\n","    fps = video.FPS().start()\n","\n","    # iterate through video frame by fame\n","    count = 0\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","\n","        # resize frame\n","        frame_resize = cv2.resize(frame, \n","                                  None, \n","                                  fx=1 / downsample_ratio, \n","                                  fy=1 / downsample_ratio)\n","        \n","        # gray scale \n","        gray = cv2.cvtColor(frame_resize, cv2.COLOR_BGR2GRAY)\n","\n","        # detect face\n","        faces = detector(gray, 1)\n","\n","        # black background\n","        black_image = np.zeros(frame.shape, np.uint8)\n","\n","        # Proceed only if face is detected\n","        if len(faces) == 1:\n","            for face in faces:\n","                # get landmarks\n","                detected_landmarks = predictor(gray, face).parts()\n","                landmarks = [[p.x * downsample_ratio, p.y * downsample_ratio] for p in detected_landmarks]\n","\n","                # get landmark features\n","                jaw = reshape_array(landmarks[0:17])\n","                left_eyebrow = reshape_array(landmarks[22:27])\n","                right_eyebrow = reshape_array(landmarks[17:22])\n","                nose_bridge = reshape_array(landmarks[27:31])\n","                lower_nose = reshape_array(landmarks[30:35])\n","                left_eye = reshape_array(landmarks[42:48])\n","                right_eye = reshape_array(landmarks[36:42])\n","                outer_lip = reshape_array(landmarks[48:60])\n","                inner_lip = reshape_array(landmarks[60:68])\n","\n","                # plot landmarks\n","                color = (255, 255, 255)\n","                thickness = 3\n","\n","                cv2.polylines(black_image, [jaw], False, color, thickness)\n","                cv2.polylines(black_image, [left_eyebrow], False, color, thickness)\n","                cv2.polylines(black_image, [right_eyebrow], False, color, thickness)\n","                cv2.polylines(black_image, [nose_bridge], False, color, thickness)\n","                cv2.polylines(black_image, [lower_nose], True, color, thickness)\n","                cv2.polylines(black_image, [left_eye], True, color, thickness)\n","                cv2.polylines(black_image, [right_eye], True, color, thickness)\n","                cv2.polylines(black_image, [outer_lip], True, color, thickness)\n","                cv2.polylines(black_image, [inner_lip], True, color, thickness)\n","\n","            # Display the resulting frame\n","            count += 1\n","            cv2.imwrite(\"original/{}.png\".format(count), frame)\n","            cv2.imwrite(\"landmarks/{}.png\".format(count), black_image)\n","            fps.update()\n","\n","            # stop after num_samples\n","            if count == num_samples:  \n","                break\n","            elif cv2.waitKey(1) & 0xFF == ord('q'):\n","                break\n","        else:\n","            print(\"No face detected\")\n","\n","    fps.stop()\n","    print('Total time: {:.2f}'.format(fps.elapsed()))\n","    print('Approx. FPS: {:.2f}'.format(fps.fps()))\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"],"outputs":[],"metadata":{"id":"K5GvNU4ak4jJ"}},{"cell_type":"code","execution_count":null,"source":["# get landmarks model if not already available\n","!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n","!bunzip2 \"shape_predictor_68_face_landmarks.dat.bz2\""],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# instantiate objects for face and landmark detection\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"],"outputs":[],"metadata":{"id":"s5ta8BFNk9ID"}},{"cell_type":"code","execution_count":null,"source":["# prepare data\n","prepare_data('obama.mp4', \n","             detector, \n","             predictor,\n","             num_samples=400, \n","             downsample_ratio = DOWNSAMPLE_RATIO)"],"outputs":[],"metadata":{"id":"mrntYluSlZTt"}},{"cell_type":"code","execution_count":null,"source":["# zip landmarks\n","!zip landmarks.zip landmarks/*.*"],"outputs":[],"metadata":{"id":"qwfzW6iHsUoc"}},{"cell_type":"code","execution_count":null,"source":["# zip original fames\n","!zip original.zip original/*.*"],"outputs":[],"metadata":{"id":"s2NvDLsess-e"}}]}